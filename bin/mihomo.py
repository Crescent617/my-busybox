#!/usr/bin/env python3

"""
mihomo.py æ˜¯ä¸€ä¸ªæ— ä»»ä½•ç¬¬ä¸‰æ–¹pyåŒ…ä¾èµ– Python è„šæœ¬ï¼Œç”¨äºç®¡ç† Clash é…ç½®æ–‡ä»¶ã€è®¢é˜…æ›´æ–°å’Œä»£ç†åˆ‡æ¢ã€‚
è¯¥è„šæœ¬åŒ…æ‹¬ä»¥ä¸‹ä¸»è¦åŠŸèƒ½ï¼š
1. ä¸‹è½½è®¢é˜…æ–‡ä»¶å¹¶ä¸æœ¬åœ°é…ç½®æ–‡ä»¶è¿›è¡Œåˆå¹¶ã€‚
2. è‡ªåŠ¨ä¸‹è½½ UI ç»„ä»¶å’Œ MaxMind åœ°ç†æ•°æ®åº“æ–‡ä»¶ã€‚
3. æµ‹è¯•ä»£ç†èŠ‚ç‚¹çš„å»¶è¿Ÿå¹¶åˆ‡æ¢è‡³æœ€ä½³èŠ‚ç‚¹ã€‚
4. æä¾› CLI æ¥å£ä¾›ç”¨æˆ·æ“ä½œã€‚

ä¾èµ–é¡¹ï¼š
- yq å’Œ git: ç”¨äº YAML åˆå¹¶åŠ UI ä¸‹è½½ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
è¯·ç¡®ä¿è®¾ç½®ç¯å¢ƒå˜é‡ `CLASH_SUB_URL` æˆ–åœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®šè®¢é˜… URLã€‚
è¿è¡Œè„šæœ¬æ—¶ï¼š
`python3 mihomo.py <commands>`
æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¥æŸ¥çœ‹æ”¯æŒçš„å…¨éƒ¨åŠŸèƒ½ï¼š
`python3 mihomo.py --help`
"""

import json
import logging
import os
import re
import subprocess
import sys
import tempfile
import urllib.parse
import urllib.request
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Literal

from minifire import fire_like

# ==== é…ç½®éƒ¨åˆ† ====
PROXY_SELECTOR = re.compile(r"é¦™æ¸¯|æ–°åŠ å¡|å°æ¹¾|æ—¥æœ¬")  # ä»£ç†èŠ‚ç‚¹é€‰æ‹©è§„åˆ™
TARGET_GROUP = "ğŸ”°å›½å¤–æµé‡"  # Clash ç­–ç•¥ç»„åç§°
TEST_DELAY_URL = "http://google.com"  # ç”¨äºæµ‹è¯•ä»£ç†èŠ‚ç‚¹å»¶è¿Ÿçš„ URL

# ==== æ—¥å¿—è®¾ç½® ====
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger(__name__)

# ==== å¸¸é‡å®šä¹‰ ====
MIHOMO_DIR = Path(os.getenv("MIHOMO_DIR") or "~/.config/mihomo").expanduser()
MIHOMO_DIR.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºé…ç½®ç›®å½•
DEFAULT_CONFIG = (Path(__file__).parent / "data" / "mihomo_default.yaml").read_text()
CUSTOM_RULES = (Path(__file__).parent / "data" / "mihomo_rules.yaml").read_text()
CLASH_HOST = "http://0.0.0.0:9090"  # Clash æ§åˆ¶å°åœ°å€
SECRET = ""  # Clash çš„ API å¯†é’¥ï¼Œå¦‚æœéœ€è¦ï¼Œè¯·å¡«å†™ã€‚

# ==== å‡½æ•°å®šä¹‰ ====
def run_cmd(cmd: str, check=True):
    """è¿è¡Œå‘½ä»¤è¡ŒæŒ‡ä»¤ï¼Œå¹¶æ•è·è¾“å‡º"""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if check and result.returncode != 0:
        logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {cmd}")
        logger.error(result.stderr)
        sys.exit(1)
    return result.stdout.strip()

def download_config(sub_url: str):
    """ä¸‹è½½è®¢é˜…é…ç½®å¹¶åˆå¹¶ä¸º Clash çš„é…ç½®æ–‡ä»¶"""
    if not sub_url:
        logger.error("è¯·è®¾ç½® SUB_URL")
        sys.exit(1)

    logger.info("ä¸‹è½½è®¢é˜…ä¸­...")

    config_file = MIHOMO_DIR / "config.yaml"

    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å¤¹è¿›è¡Œé…ç½®å¤„ç†
    with tempfile.TemporaryDirectory() as temp_dir:
        p = Path(temp_dir)

        sub_config = p / "sub.yaml"
        default_config = p / "config_default.yaml"
        rules_file = p / "rules.yaml"

        # å†™å…¥é»˜è®¤é…ç½®ä¸è§„åˆ™
        default_config.write_text(DEFAULT_CONFIG)
        rules_file.write_text(CUSTOM_RULES)

        try:
            # ä¸‹è½½è®¢é˜…æ–‡ä»¶
            urllib.request.urlretrieve(sub_url, sub_config)
        except Exception as e:
            logger.error(f"ä¸‹è½½è®¢é˜…å¤±è´¥: {e}")
            sys.exit(1)

        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä¸‹è½½äº† proxies å­—æ®µ
        try:
            output = run_cmd(f"yq -r '.proxies' {sub_config}")
            if not output:
                raise Exception("è®¢é˜… proxies å­—æ®µä¸ºç©º")
        except Exception as e:
            logger.error(f"è§£æè®¢é˜…å¤±è´¥æˆ–æ—  proxies: {e}")
            sys.exit(1)

        logger.info("åˆå¹¶é…ç½®æ–‡ä»¶...")
        merged_yaml = run_cmd(
            f"yq eval-all 'select(fi == 0) *+ select(fi == 1) * select(fi == 2)' {rules_file} {sub_config} {default_config}"
        )
        config_file.write_text(merged_yaml)

def download_ui():
    """ä¸‹è½½ UI ç»„ä»¶"""
    ui_dir = MIHOMO_DIR / "ui"
    if ui_dir.exists():
        logger.info("UI å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        return
    logger.info("ä¸‹è½½ UI...")
    run_cmd(
        f"git clone https://github.com/metacubex/metacubexd.git -b gh-pages --depth 1 {ui_dir}"
    )

def download_mmdb():
    """ä¸‹è½½ MaxMind MMDB æ–‡ä»¶"""
    mmdb_path = MIHOMO_DIR / "Country.mmdb"
    system_mmdb = Path("/etc/clash/Country.mmdb")
    if system_mmdb.exists():
        logger.info("æ£€æµ‹åˆ°ç³»ç»Ÿå·²å®‰è£… mmdb æ–‡ä»¶ï¼Œè·³è¿‡ä¸‹è½½")
        if mmdb_path.exists():
            mmdb_path.unlink()
        os.symlink(system_mmdb, mmdb_path)
        return

    temp_path = Path(tempfile.gettempdir()) / "Country.mmdb.temp"
    if not temp_path.exists():
        logger.info("ä¸‹è½½ mmdb æ–‡ä»¶...")
        url = "https://cdn.jsdelivr.net/gh/Dreamacro/maxmind-geoip@release/Country.mmdb"
        try:
            urllib.request.urlretrieve(url, temp_path)
        except Exception as e:
            logger.error(f"ä¸‹è½½ mmdb æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    os.rename(temp_path, mmdb_path)

# æ„é€ å¸¦ secret çš„ URL
def build_url(path, query=None):
    base = urllib.parse.urljoin(CLASH_HOST, path)
    query = query or {}
    if SECRET:
        query["secret"] = SECRET
    if query:
        return f"{base}?{urllib.parse.urlencode(query)}"
    return base

# å‘é€ GET è¯·æ±‚å¹¶è¿”å› JSON
def http_get_json(url):
    req = urllib.request.Request(url)
    with urllib.request.urlopen(req, timeout=10) as resp:
        return json.loads(resp.read().decode())

# å‘é€ PUT è¯·æ±‚
def http_put_json(url, data):
    body = json.dumps(data).encode()
    req = urllib.request.Request(url, data=body, method="PUT")
    req.add_header("Content-Type", "application/json")
    with urllib.request.urlopen(req, timeout=10) as resp:
        return resp.read().decode()

# è·å–ç­–ç•¥ç»„ä¸‹çš„æ‰€æœ‰èŠ‚ç‚¹å
def get_proxies():
    url = build_url("/proxies")
    data = http_get_json(url)
    proxies: dict[str, dict] = data.get("proxies", [])
    targets = []

    for name, proxy in proxies.items():
        if proxy.get("id") and proxy.get("name") and PROXY_SELECTOR.search(name):
            targets.append(proxy["name"])
    return targets

# æµ‹è¯•æŸä¸ªèŠ‚ç‚¹çš„å»¶è¿Ÿ
def test_delay(proxy_name: str):
    encoded = urllib.parse.quote(proxy_name.encode(), safe="")
    url = build_url(
        f"/proxies/{encoded}/delay",
        {"timeout": 5000, "url": TEST_DELAY_URL},
    )
    try:
        data = http_get_json(url)
        return data.get("delay", float("inf"))
    except:
        return float("inf")

# åˆ‡æ¢ç­–ç•¥ç»„ä½¿ç”¨çš„èŠ‚ç‚¹
def switch_proxy(proxy_name: str):
    encoded = urllib.parse.quote(TARGET_GROUP, safe="")
    url = build_url(f"/proxies/{encoded}")
    http_put_json(url, {"name": proxy_name})
    logger.info(f"âœ… å·²åˆ‡æ¢åˆ°èŠ‚ç‚¹ï¼š{proxy_name}")

def load_json(file_path: Path):
    """åŠ è½½ JSON æ–‡ä»¶"""
    if not file_path.exists():
        return {}
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

class Cli:
    """CLI å‘½ä»¤è¡Œæ§åˆ¶ç±»"""
    def __init__(self, sub_url: str = "", dir=MIHOMO_DIR):
        self.mihomo_dir = Path(dir).expanduser()
        self.sub_url = (
            sub_url
            or load_json(self.mihomo_dir / "subconfig.json").get("sub_url")
            or os.getenv("CLASH_SUB_URL")
        )

    def download(self, file: Literal["config", "ui", "mmdb", "all"]):
        """ä¸‹è½½é…ç½®ã€UI æˆ– mmdb æ–‡ä»¶"""

        sub_url = self.sub_url
        if not sub_url:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ CLASH_SUB_URL")
        actions = {
            "config": lambda: download_config(sub_url),
            "ui": download_ui,
            "mmdb": download_mmdb,
            "all": lambda: (download_config(sub_url), download_ui(), download_mmdb()),
        }
        actions[file]()

    def update_sub(self):
        """æ›´æ–°è®¢é˜…"""
        self.download("config")

    def run(self):
        """è¿è¡Œ Mihomo"""
        logger.info("å¯åŠ¨ mihomo...")
        run_cmd(f"mihomo -d {self.mihomo_dir}")

    def proxy(self, show: bool = False, auto: bool = False):
        """åˆ‡æ¢ä»£ç†èŠ‚ç‚¹"""
        proxies = get_proxies()

        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {executor.submit(test_delay, proxy): proxy for proxy in proxies}
            delays = {future.result(): proxy for future, proxy in futures.items()}
            if delays and auto:
                min_delay = min(delays.keys())
                best_proxy = delays[min_delay]
                logger.info(f"æœ€ä½³èŠ‚ç‚¹: {best_proxy} (å»¶è¿Ÿ: {min_delay} ms)")
                switch_proxy(best_proxy)

            elif show:
                logger.info("å¯ç”¨èŠ‚ç‚¹åˆ—è¡¨:")
                for d, proxy in sorted(delays.items()):
                    logger.info(f"{proxy} - å»¶è¿Ÿ: {d} ms")

    def healthcheck(self):
        req = urllib.request.Request(TEST_DELAY_URL)
        try:
            urllib.request.urlopen(req, timeout=10)
            logger.info("ping æµ‹è¯•æˆåŠŸï¼Œç½‘ç»œè¿æ¥æ­£å¸¸")
        except Exception as e:
            logger.error(f"ping å¤±è´¥: {e}... å°è¯•åˆ‡æ¢ä»£ç†")
            self.proxy(auto=True)


if __name__ == "__main__":
    try:
        fire_like(Cli)
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {str(e)[:50]}")
        sys.exit(1)
